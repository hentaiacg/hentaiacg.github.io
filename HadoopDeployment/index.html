<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Hadoop 集群安装 | Rishinyan</title><meta name="author" content="Rishinyan,shinyanri@gmail.com"><meta name="copyright" content="Rishinyan"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Hadoop 集群安装部署文档">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop 集群安装">
<meta property="og:url" content="https://blog.rishinyan.top/HadoopDeployment/">
<meta property="og:site_name" content="Rishinyan">
<meta property="og:description" content="Hadoop 集群安装部署文档">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://ff09945.webp.li/MorishimaHaruka_3.png">
<meta property="article:published_time" content="2022-03-31T16:00:00.000Z">
<meta property="article:modified_time" content="2025-03-14T09:34:51.000Z">
<meta property="article:author" content="Rishinyan">
<meta property="article:tag" content="Hadoop">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://ff09945.webp.li/MorishimaHaruka_3.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Hadoop 集群安装",
  "url": "https://blog.rishinyan.top/HadoopDeployment/",
  "image": "https://ff09945.webp.li/MorishimaHaruka_3.png",
  "datePublished": "2022-03-31T16:00:00.000Z",
  "dateModified": "2025-03-14T09:34:51.000Z",
  "author": [
    {
      "@type": "Person",
      "name": "Rishinyan",
      "url": "https://blog.rishinyan.top/"
    }
  ]
}</script><link rel="shortcut icon" href="https://ff09945.webp.li/watch_neko.jpg"><link rel="canonical" href="https://blog.rishinyan.top/HadoopDeployment/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//static.cloudflareinsights.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script defer="defer" data-pjax="data-pjax" src="https://static.cloudflareinsights.com/beacon.min.js" data-cf-beacon="{&quot;token&quot;: &quot;50a7ba8f0875473cb18b83fd39f34467&quot;}"></script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":200,"highlightFullpage":false,"highlightMacStyle":true},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":150,"languages":{"author":"作者: Rishinyan","link":"链接: ","source":"来源: Rishinyan","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'medium_zoom',
  Snackbar: {"chs_to_cht":"已切换为繁体中文","cht_to_chs":"已切换为简体中文","day_to_night":"已切换为深色模式","night_to_day":"已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"bottom-left"},
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: true,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Hadoop 集群安装',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><link rel="stylesheet" href="/css/wave.css"><link rel="stylesheet" href="/css/mouse.css"><link rel="stylesheet" href="/css/progress_bar.css"><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="Rishinyan" type="application/atom+xml">
</head><body><div id="loading-box" onclick="document.getElementById(&quot;loading-box&quot;).classList.add(&quot;loaded&quot;)"><div class="loading-bg"><div class="loading-img"></div><div class="loading-image-dot"></div></div></div><script>const preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',()=> { preloader.endLoading() })

if (false) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><script>window.paceOptions = {
  restartOnPushState: false
}

btf.addGlobalFn('pjaxSend', () => {
  Pace.restart()
}, 'pace_restart')

</script><link rel="stylesheet" href="/css/progress_bar.css"/><script src="https://cdn.jsdelivr.net/npm/pace-js/pace.min.js"></script><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="https://ff09945.webp.li/watch_neko.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">7</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">3</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">2</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/Jeff/"><i class="fa-fw fas fa-female"></i><span> Jeff</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> CS</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/BigData/"><i class="fa-fw fas fa-database"></i><span> BigData</span></a></li><li><a class="site-page child" href="/MachineLearning/"><i class="fa-fw fas fa-microchip-ai"></i><span> MachineLearning</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://ff09945.webp.li/MorishimaHaruka_3.png);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"></a><a class="nav-page-title" href="/"><span class="site-name">Hadoop 集群安装</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/Jeff/"><i class="fa-fw fas fa-female"></i><span> Jeff</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> CS</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/BigData/"><i class="fa-fw fas fa-database"></i><span> BigData</span></a></li><li><a class="site-page child" href="/MachineLearning/"><i class="fa-fw fas fa-microchip-ai"></i><span> MachineLearning</span></a></li></ul></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">Hadoop 集群安装</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-03-31T16:00:00.000Z" title="发表于 2022-04-01 00:00:00">2022-04-01</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-03-14T09:34:51.000Z" title="更新于 2025-03-14 17:34:51">2025-03-14</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/BigData/">BigData</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><!-- display waves--><section class="main-hero-waves-area waves-area"><svg class="waves-svg" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M -160 44 c 30 0 58 -18 88 -18 s 58 18 88 18 s 58 -18 88 -18 s 58 18 88 18 v 44 h -352 Z"></path></defs><g class="parallax"><use href="#gentle-wave" x="48" y="0"></use><use href="#gentle-wave" x="48" y="3"></use><use href="#gentle-wave" x="48" y="5"></use><use href="#gentle-wave" x="48" y="7"></use></g></svg></section></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><div id="post-outdate-notice" data="{&quot;limitDay&quot;:365,&quot;messagePrev&quot;:&quot;It has been&quot;,&quot;messageNext&quot;:&quot;days since the last update, the content of the article may be outdated.&quot;,&quot;postUpdate&quot;:&quot;2025-03-14 17:34:51&quot;}" hidden></div><h1>Hadoop</h1>
<h2 id="修改Linux的主机映射文件">修改Linux的主机映射文件</h2>
<p>请确保<strong>所有节点</strong>的用户均相同；如，都有rishinyan用户.</p>
<p>如果没有用户名相同的用户，请使用root用户来创建用户</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 使用root用户</span><br><span class="line">su root</span><br><span class="line"># 新建用户</span><br><span class="line">useradd rishinyan</span><br><span class="line"># 给用户设置密码，将输入两次，最后一次为确认密码</span><br><span class="line">passwd rishinyan123</span><br></pre></td></tr></table></figure>
<p>使用root用户编辑sudoers文件，赋予rishinyan用户权限</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 编辑sudoers文件</span><br><span class="line">vi /etc/sudoers</span><br><span class="line"></span><br><span class="line"># 找到root	ALL=(ALL)	ALL</span><br><span class="line"># 按i进入编辑,在其下方输入</span><br><span class="line">rishinyan	ALL=(ALL)	ALL</span><br></pre></td></tr></table></figure>
<p>先按下<strong>esc键</strong>，后输入:wq!保存并退出编辑</p>
<p>所有节点均要有rishinyan用户</p>
<p>修改<strong>所有节点</strong>的hosts文件，方便我们在Linux里面通过主机名访问服务器</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 通过命令su切换用户rishinyan</span><br><span class="line">su rishinyan</span><br><span class="line"># 添加节点，执行sudo命令会要求输入密码，输入创建rishinyan用户时所设置的密码</span><br><span class="line">sudo vi /etc/hosts</span><br></pre></td></tr></table></figure>
<p>按i进入编辑，并添加如下内容，前面为ip，后面为对应的映射名</p>
<p>这里，有五台服务器，将192.168.2.246与192.168.2.247设置为主节点；192.168.2.248，192.168.2.249和192.168.2.250设置为数据节点</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">192.168.2.246 master1</span><br><span class="line">192.168.2.247 master2</span><br><span class="line">192.168.2.248 slave1</span><br><span class="line">192.168.2.249 slave2</span><br><span class="line">192.168.2.250 slave3</span><br></pre></td></tr></table></figure>
<p>先按下<strong>esc</strong>，后输入:wq!保存并退出编辑</p>
<h2 id="关闭Selinux和防火墙">关闭Selinux和防火墙</h2>
<p><strong>所有节点</strong>均需关闭Selinux和防火墙</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># setenforce 0</span><br><span class="line"># 编辑配置文件</span><br><span class="line"># vi /etc/selinux/config</span><br><span class="line"></span><br><span class="line">SELINUX=disabled</span><br><span class="line"></span><br><span class="line"># 查看防火墙状态</span><br><span class="line">sudo systemctl status firewalld</span><br><span class="line"># 执行关闭命令，会提示输入root用户密码，输入密码即可</span><br><span class="line">sudo systemctl stop firewalld</span><br><span class="line"># 再次执行查看防火墙命令</span><br><span class="line">sudo systemctl status firewalld </span><br><span class="line"># 执行开机禁用防火墙自启命令，会提示输入密码,输入两次root用户的密码</span><br><span class="line">sudo systemctl disable firewalld</span><br></pre></td></tr></table></figure>
<p>查看防火墙，Actice为active(running)表示防火墙开启</p>
<p>查看防火墙，Active为inactive(dead)表示防火墙关闭</p>
<h2 id="SSH免密登录配置">SSH免密登录配置</h2>
<p>所有节点都要判断是否安装了ssh服务</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm -qa | grep openssh</span><br></pre></td></tr></table></figure>
<p>如果没有出现openssh相关信息，则安装ssh服务</p>
<p>1.主节点的免密钥配置</p>
<p>对于master1和master2,slave1</p>
<p>（1）生成公钥和私钥</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa</span><br><span class="line"># 按三次回车</span><br></pre></td></tr></table></figure>
<p>（2）将公钥拷贝到要免密登录的目标机器上</p>
<p>对于master1和master2</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># master1可替换为/etc/hosts文件中对应的ip，192.168.2.246</span><br><span class="line"># 执行命令后，先输入yes，再回车，之后再输入rishinyan用户的密码。下同</span><br><span class="line">ssh-copy-id master1</span><br><span class="line"></span><br><span class="line"># master2可替换为/etc/hosts文件中对应的ip，192.168.2.247</span><br><span class="line">ssh-copy-id master2</span><br><span class="line"></span><br><span class="line"># slave1可替换为/etc/hosts文件中对应的ip，192.168.2.248</span><br><span class="line">ssh-copy-id slave1</span><br><span class="line"></span><br><span class="line"># slave2可替换为/etc/hosts文件中对应的ip，192.168.2.249</span><br><span class="line">ssh-copy-id slave2</span><br><span class="line"></span><br><span class="line"># slave3可替换为/etc/hosts文件中对应的ip，192.168.2.250</span><br><span class="line">ssh-copy-id slave3</span><br></pre></td></tr></table></figure>
<p>对于slave1,hbase需要免密连接slave2和slave3</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># slave1可替换为/etc/hosts文件中对应的ip，192.168.2.248</span><br><span class="line">ssh-copy-id slave1</span><br><span class="line"></span><br><span class="line"># slave2可替换为/etc/hosts文件中对应的ip，192.168.2.249</span><br><span class="line">ssh-copy-id slave2</span><br><span class="line"></span><br><span class="line"># slave3可替换为/etc/hosts文件中对应的ip，192.168.2.250</span><br><span class="line">ssh-copy-id slave3</span><br></pre></td></tr></table></figure>
<p>注：.ssh文件夹下（~/.ssh）的文件功能解释</p>
<ol>
<li>known_hosts	：记录ssh访问过计算机的公钥(public key)</li>
<li>id_rsa	：生成的私钥</li>
<li>id_rsa.pub	：生成的公钥</li>
<li>authorized_keys	：存放授权过的可以免密登录本服务器的其它机器的公钥</li>
</ol>
<p>2.验证</p>
<p>在master1输入</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ssh slave1</span><br><span class="line"># 或</span><br><span class="line">ssh rishinyan@slave1</span><br></pre></td></tr></table></figure>
<p>rishinyan为用户名；slave1为/etc/hosts文件中的映射名</p>
<p>无需输入密码便可登陆。slave1可替换为master1，master2，slave2，slave3</p>
<p>master2也需做相同的操作</p>
<h2 id="设置时间同步">设置时间同步</h2>
<p>当前采用master1作为时间同步服务端</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">管理节点：</span><br><span class="line">    #yum install chrony</span><br><span class="line">    #cp /etc/chrony.conf /etc/chrony.conf.bak</span><br><span class="line">    #vim /etc/chrony.conf(注释前4行，新增3行内容)</span><br><span class="line">    #server 0.centos.pool.ntp.org iburst</span><br><span class="line">    #server 1.centos.pool.ntp.org iburst</span><br><span class="line">    #server 2.centos.pool.ntp.org iburst</span><br><span class="line">    #server 3.centos.pool.ntp.org iburst</span><br><span class="line">    server 192.168.2.246 iburst</span><br><span class="line">    allow 192.168.2.0/24</span><br><span class="line">    local stratum 10</span><br><span class="line">    sudo systemctl start chronyd</span><br><span class="line">    sudo systemctl enable chronyd</span><br><span class="line"></span><br><span class="line">客户端节点</span><br><span class="line">    #yum install chrony</span><br><span class="line">    #cp /etc/chrony.conf /etc/chrony.conf.bak</span><br><span class="line">    #vi  /etc/chrony.conf(注释前4行，新增1行内容)</span><br><span class="line">    #server 0.centos.pool.ntp.org iburst</span><br><span class="line">    #server 1.centos.pool.ntp.org iburst</span><br><span class="line">    #server 2.centos.pool.ntp.org iburst</span><br><span class="line">    #server 3.centos.pool.ntp.org iburst</span><br><span class="line">    server 192.168.2.246 iburst</span><br><span class="line">    #systemctl start chronyd</span><br><span class="line">    #systemctl enable chronyd</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="JDK安装">JDK安装</h2>
<h3 id="准备">准备</h3>
<ol>
<li>在所有节点，新建用于存放安装软件的目录</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 安装软件的目录</span><br><span class="line">mkdir ~/module</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>将所需的安装包全部放入~/installed目录下</li>
</ol>
<h3 id="安装步骤">安装步骤</h3>
<h4 id="主节点master1解压jdk-8u281-linux-x64-tar-gz的压缩包">主节点master1解压jdk-8u281-linux-x64.tar.gz的压缩包</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#将jdk解压到/rishinyan/module/jdk1.8.0_281</span><br><span class="line">tar -zxvf ~/installed/Java-1.8/jdk-8u281-linux-x64.tar.gz -C ~/module</span><br><span class="line"></span><br><span class="line">#将解压后的文件夹重命名为java</span><br><span class="line">mv ~/module/jdk1.8.0_281/ ~/module/java</span><br></pre></td></tr></table></figure>
<h4 id="配置jdk环境变量-bashrc">配置jdk环境变量~/.bashrc</h4>
<p><strong>所有节点</strong>均需要配置环境变量（.bashrc 或 .bash_profile 均可）文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi ~/.bashrc</span><br></pre></td></tr></table></figure>
<p>按i进入编辑，在文件尾部添加如下内容</p>
<p>注：JAVA_HOME为jdk的解压路径，对应上面-C后的路径，如果解压路径改变，这里也将相应的改变</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># Java</span><br><span class="line">export JAVA_HOME=/home/rishinyan/module/java</span><br><span class="line">export PATH=$JAVA_HOME/bin:$PATH</span><br></pre></td></tr></table></figure>
<p>先按下<strong>esc</strong>，后输入:wq!保存并退出编辑</p>
<h4 id="测试是否安装成功">测试是否安装成功</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">source ~/.bash_profile</span><br><span class="line">java -version</span><br></pre></td></tr></table></figure>
<p>当出现openjdk version “1.8.0_281”，则说明安装成功。</p>
<h4 id="将解压好的jdk分发给其他节点">将解压好的jdk分发给其他节点</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># master2可替换为/etc/hosts文件中对应的ip，192.168.2.247</span><br><span class="line">scp -r ~/module/java master2:~/module</span><br><span class="line"># slave1可替换为/etc/hosts文件中对应的ip，192.168.2.248</span><br><span class="line">scp -r ~/module/java  slave1:~/module</span><br><span class="line"># slave2可替换为/etc/hosts文件中对应的ip，192.168.2.249</span><br><span class="line">scp -r ~/module/java  slave2:~/module</span><br><span class="line"># slave3可替换为/etc/hosts文件中对应的ip，192.168.2.250</span><br><span class="line">scp -r ~/module/java  slave3:~/module</span><br></pre></td></tr></table></figure>
<h4 id="配置各个节点的Java环境变量">配置各个节点的Java环境变量</h4>
<p>切换至集群其他节点，分别执行4.2.2及4.2.3的步骤，配置各个节点的Java环境变量</p>
<h2 id="zookeeper安装">zookeeper安装</h2>
<h3 id="准备-2">准备</h3>
<p>选择需要安装zookeeper的节点（节点个数通常为奇数，至少三个节点），<br>
本次选择slave1、slave2、slave3三个节点安装部署zookeeper。</p>
<p>在数据节点中选择一个,如slave1节点，~/installed目录中存在apache-zookeeper-3.7.1-bin.tar.gz的压缩包</p>
<h3 id="安装步骤-2">安装步骤</h3>
<h4 id="解压apache-zookeeper-3-7-1-bin-tar-gz到指定目录-module-下">解压apache-zookeeper-3.7.1-bin.tar.gz到指定目录~/module/下</h4>
<p>这里我选择slave1节点</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#将zookeeper解压到/rishinyan/package/apache-zookeeper-3.7.1-bin</span><br><span class="line">tar -zxvf ~/installed/Zookeeper-3.7.1/apache-zookeeper-3.7.1-bin.tar.gz -C ~/module/</span><br><span class="line"></span><br><span class="line">#将apache-zookeeper-3.7.1-bin重命名为zookeeper</span><br><span class="line">mv ~/module/apache-zookeeper-3.7.1-bin/ ~/module/zookeeper</span><br></pre></td></tr></table></figure>
<h4 id="创建目录，用来存放数据和日志">创建目录，用来存放数据和日志</h4>
<p><strong>所有zookeeper节点都需要创建~/data/zkData和~/logs/zookeeper</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># ~/data/zkData 存放数据</span><br><span class="line">mkdir -p ~/data/zkData</span><br><span class="line"></span><br><span class="line">#~/logs/zookeeper 存放日志</span><br><span class="line">mkdir -p ~/logs/zookeeper</span><br></pre></td></tr></table></figure>
<h4 id="重命名zoo-sample-cfg为zoo-cfg">重命名zoo_sample.cfg为zoo.cfg</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp ~/module/zookeeper/conf/zoo_sample.cfg ~/module/zookeeper/conf/zoo.cfg</span><br></pre></td></tr></table></figure>
<h4 id="修改配置文件">修改配置文件</h4>
<p>修改或添加以下配置</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">vi ~/module/zookeeper/conf/zoo.cfg</span><br><span class="line"># 按i进入编辑</span><br><span class="line"># 修改存放数据的路径，设置为解压zookeeper的路径下的zkData目录</span><br><span class="line"># rishinyan为用户目录</span><br><span class="line">dataDir=/home/rishinyan/data/zkData</span><br><span class="line"></span><br><span class="line"># 在末尾添加zookeeper集群的ip和端口</span><br><span class="line"># slave1为hosts中映射的主机名，可替换为192.168.2.248:2888:3888</span><br><span class="line"># slave2为hosts中映射的主机名，可替换为192.168.2.249:2888:3888</span><br><span class="line"># slave3为hosts中映射的主机名，可替换为192.168.2.250:2888:3888</span><br><span class="line">server.1=slave1:2888:3888</span><br><span class="line">server.2=slave2:2888:3888</span><br><span class="line">server.3=slave3:2888:3888</span><br></pre></td></tr></table></figure>
<p>先按下<strong>esc</strong>，后输入:wq!保存并退出编辑</p>
<p>配置参数解读	server.A=B:C:D</p>
<p>A是一个数字，表示这个是第几号服务器；</p>
<p>B是这个服务器的ip地址；</p>
<p>C是这个服务器与集群中的Leader服务器交换信息的端口；</p>
<p>D是万一集群中的Leader服务器挂了，需要一个端口来重新进行选举，选出一个新的Leader，而这个端口就是用来执行选举时服务器相互通信的端口。</p>
<p>集群模式下配置一个文件myid，这个文件在dataDir目录下，这个文件里面有一个数据就是A的值，Zookeeper启动时读取此文件，拿到里面的数据与zoo.cfg里面的配置信息比较从而判断到底是哪个server。</p>
<p><font color='red'>注意，zookeeper节点的数量一定是奇数，且不少于三个节点</font></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vi ~/module/zookeeper/bin/zkEnv.sh</span><br><span class="line"># 按i进入编辑</span><br><span class="line"># 修改日志数据的路径</span><br><span class="line">ZOO_LOG_DIR=/home/rishinyan/logs/zookeeper</span><br></pre></td></tr></table></figure>
<h4 id="在zkData目录下创建一个myid的文件">在zkData目录下创建一个myid的文件</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 创建myid文件</span><br><span class="line">touch ~/data/zkData/myid</span><br></pre></td></tr></table></figure>
<h4 id="编辑myid文件">编辑myid文件</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi ~/data/zkData/myid</span><br></pre></td></tr></table></figure>
<p>在文件中添加与server对应的编号</p>
<p>zoo.cfg文件中server.1=slave1:2888:3888中slave1对应server.1。则在myid文件中输入1</p>
<p>按i进入编辑。结束后先按下<strong>esc</strong>，后输入:wq!保存并退出编辑</p>
<h4 id="配置zookeeper环境变量-bashrc">配置zookeeper环境变量~/.bashrc</h4>
<p>在slave1，slave2，slave3节点均需配置</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi ~/.bashrc</span><br></pre></td></tr></table></figure>
<p>按i进入编辑，在.bashrc文件尾部添加如下内容</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># ZOOKEEPER_HOME为zookeeper的解压路径，对应上面-C后的路径，如果解压路径改变，这里也将相应的改变</span><br><span class="line">export ZOOKEEPER_HOME=/home/rishinyan/module/zookeeper</span><br><span class="line">export PATH=$PATH:$ZOOKEEPER_HOME/bin</span><br></pre></td></tr></table></figure>
<p>先按下<strong>esc</strong>，后输入:wq!保存并退出编辑</p>
<h4 id="拷贝配置好的zookeeper分发到其他数据节点上">拷贝配置好的zookeeper分发到其他数据节点上</h4>
<p>这里我配置在slave1上，所以要分发到slave2和slave3</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># slave2可替换为/etc/hosts文件中对应的ip，192.168.2.249</span><br><span class="line">scp -r ~/module/zookeeper  slave2:~/module</span><br><span class="line"># slave3可替换为/etc/hosts文件中对应的ip，192.168.2.250</span><br><span class="line">scp -r ~/module/zookeeper  slave3:~/module</span><br></pre></td></tr></table></figure>
<h4 id="其他数据节点修改分发节点的myid文件">其他数据节点修改分发节点的myid文件</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p ~/data/zkData</span><br><span class="line">vi ~/data/zkData/myid</span><br></pre></td></tr></table></figure>
<p>将id改为/rishinyan/module/zookeeper/conf/zoo.cfg文件中对应ip的server对应的编号</p>
<p>如slave2的myid为2,slave3的myid为3</p>
<h4 id="所有数据节点启动zookeeper">所有数据节点启动zookeeper</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">~/module/zookeeper/bin/zkServer.sh start</span><br></pre></td></tr></table></figure>
<h3 id="查看状态">查看状态</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">~/module/zookeeper/bin/zkServer.sh status</span><br></pre></td></tr></table></figure>
<p>每个节点安装并启动成功后，Mode会显示follower或leader</p>
<h2 id="HadoopHA安装">HadoopHA安装</h2>
<h3 id="准备-3">准备</h3>
<p>主节点的~/installed目录下有hadoop-3.3.4.tar.gz压缩包</p>
<p>这里我选择master1节点</p>
<h3 id="安装步骤-3">安装步骤</h3>
<h4 id="解压apache-hadoop-3-3-4-tar-gz到-rishinyan-module-目录下">解压apache-hadoop-3.3.4.tar.gz到/rishinyan/module/目录下</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf ~/installed/Hadoop-3.3.4/hadoop-3.3.4.tar.gz -C ~/module/</span><br></pre></td></tr></table></figure>
<h4 id="将hadoop配置环境变量">将hadoop配置环境变量</h4>
<p>所有节点均需配置.bashrc</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi ~/.bashrc</span><br></pre></td></tr></table></figure>
<p>按i进入编辑，在.bashrc文件尾部添加如下内容</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># HADOOP_HOME为hadoop-3.3.4.tar.gz的解压路径，如果-C后改变，这里也得修改</span><br><span class="line">export HADOOP_HOME=/home/rishinyan/module/hadoop-3.3.4</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin</span><br></pre></td></tr></table></figure>
<p>先按下<strong>esc</strong>，后输入:wq!保存并退出编辑</p>
<h4 id="测试是否安装成功-2">测试是否安装成功</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">source ~/.bash_profile</span><br><span class="line">hadoop version</span><br></pre></td></tr></table></figure>
<p>出现 Hadoop 3.2.2，则安装成功。</p>
<h4 id="数据节点配置">数据节点配置</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">vi ~/module/hadoop-3.3.4/etc/hadoop/workers</span><br><span class="line"></span><br><span class="line"># 按i进入编辑</span><br><span class="line"># 将文件修改成以下格式</span><br><span class="line"># slave1可替换为/etc/hosts文件中对应的ip，192.168.2.248</span><br><span class="line"># slave2可替换为/etc/hosts文件中对应的ip，192.168.2.249</span><br><span class="line"># slave3可替换为/etc/hosts文件中对应的ip，192.168.2.250</span><br><span class="line">slave1</span><br><span class="line">slave2</span><br><span class="line">slave3</span><br></pre></td></tr></table></figure>
<p>先按下<strong>esc</strong>，后输入:wq!保存并退出编辑</p>
<h4 id="HDFS的配置">HDFS的配置</h4>
<p>（1）配置Hadoop所使用Java的环境变量，告知hadoop我们jdk的安装目录</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">每个节点创建日志和pid目录</span><br><span class="line">mkdir -p ~/pids/hadoop</span><br><span class="line">mkdir -p ~/logs/hadoop</span><br><span class="line">mkdir -p ~/data/hadoop</span><br><span class="line"></span><br><span class="line">vi ~/module/hadoop-3.3.4/etc/hadoop/hadoop-env.sh</span><br><span class="line"># 按i进入编辑</span><br><span class="line"># 修改jdk路径，此为jdk的解压路径，如果路径改变，这里也得修改</span><br><span class="line">export JAVA_HOME=/home/rishinyan/module/java</span><br><span class="line"># 因为hdfs要启动namenode、datanode等进程，会产生pid，hadoop要把pid记录在某个位置，默认是放在/tmp下。这里修改pid文件存放位置</span><br><span class="line">export HADOOP_PID_DIR=/home/rishinyan/pids/hadoop</span><br><span class="line"># hadoop的日志存放路径</span><br><span class="line">export HADOOP_LOG_DIR=/home/rishinyan/logs/hadoop</span><br></pre></td></tr></table></figure>
<p>先按下<strong>esc</strong>，后输入:wq!保存并退出编辑</p>
<p>（2）修改Hadoop核心配置文件</p>
<p>~/module/hadoop-3.3.4/etc/hadoop/core-site.xml</p>
<p>在&lt;configuration&gt;&lt;/configuration&gt;标签中添加内容</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"> vi ~/module/hadoop-3.3.4/etc/hadoop/core-site.xml</span><br><span class="line"></span><br><span class="line">    &lt;!-- 按i进入编辑 --&gt;</span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;!-- 指定HDFS中NameNode的地址，要在master1和master2上启动namenode进程 --&gt;</span><br><span class="line">    &lt;!-- 把两个NameNode的地址组装成一个集群mycluster --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;hdfs://mycluster&lt;/value&gt; </span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;!-- 开启回收站 --&gt;</span><br><span class="line">    &lt;!-- interval在这个回收周期之内，文件实际上被移动到/user/&lt;username&gt;/.Trash的目录下，而不是马上删除掉,默认单位是分钟60*24=1440 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;fs.trash.interval&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;1440&lt;/value&gt; </span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;!-- 垃圾回收的检查间隔，时间小于或等于fs.trash.interval --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;fs.trash.checkpoint.interval&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;1440&lt;/value&gt; </span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;!-- datanode是个进程，把数据交给它后，它会把数据存储到本地磁盘，这里指定存储到磁盘的位置--&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;/rishinyan/data/hadoop/tmp&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;!-- 故障转移需要的zookeeper集群设置一下。--&gt;</span><br><span class="line">    &lt;!-- 可替换为192.168.2.248:2181,192.168.2.249:2181,192.168.2.250:2181--&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt; </span><br><span class="line">        &lt;value&gt;slave1:2181,slave2:2181,slave3:2181&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;!-- 后面hive的兼容性配置 --&gt;</span><br><span class="line">    &lt;!-- 注意配置中的root代表的是一个用户，hadoop.proxyuser.root.hosts 配置成*的意义，表示任意节点使用 hadoop 集群的代理用户 root 都能访问 hdfs 集群 --&gt;</span><br><span class="line">    &lt;!-- hadoop引入了一个安全伪装机制，使得hadoop 不允许上层系统直接将实际用户传递到hadoop层，而是将实际用户传递给一个超级代理，由此代理在hadoop上执行操作，避免任意客户端随意操作hadoop --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hadoop.proxyuser.rishinyan.hosts&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;*&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"> 　　</span><br><span class="line">    &lt;!-- hadoop.proxyuser.rishinyan.groups 表示代理用户的组所属 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hadoop.proxyuser.root.groups&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;*&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<p>先按下<strong>esc</strong>，后输入:wq!保存并退出编辑</p>
<p>（3）修改HDFS核心配置文件：</p>
<p>~/module/hadoop-3.3.4/etc/hadoop/hdfs-site.xml</p>
<p>在&lt;configuration&gt;&lt;/configuration&gt;标签中添加内容</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line">vi ~/module/hadoop-3.3.4/etc/hadoop/hdfs-site.xml</span><br><span class="line"></span><br><span class="line">    &lt;!-- 按i进入编辑 --&gt;</span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;!--副本数量--&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;3&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;!-- 完全分布式集群名称 --&gt;</span><br><span class="line">    &lt;!-- 与core-site.xml中fs.defaultFS的集群名相同 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.nameservices&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;mycluster&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;!-- 集群中NameNode节点都有哪些 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.ha.namenodes.mycluster&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;nn1,nn2&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;!-- nn1的RPC通信地址 --&gt;</span><br><span class="line">    &lt;!-- 可替换为192.168.2.246:9000 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.namenode.rpc-address.mycluster.nn1&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;master1:9000&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;!-- nn2的RPC通信地址 --&gt;</span><br><span class="line">    &lt;!-- 可替换为192.168.2.247:9000 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.namenode.rpc-address.mycluster.nn2&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;master2:9000&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;!-- nn1的http通信地址 --&gt;</span><br><span class="line">    &lt;!-- 可替换为192.168.2.246:9870 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.namenode.http-address.mycluster.nn1&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;master1:9870&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;!-- nn2的http通信地址 --&gt;</span><br><span class="line">    &lt;!-- 可替换为192.168.2.247:9870 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.namenode.http-address.mycluster.nn2&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;master2:9870&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">	</span><br><span class="line">    &lt;!-- 指定NameNode元数据在JournalNode上的存放位置 --&gt;</span><br><span class="line">    &lt;!-- 当editlog发生改变，则直接写入JournalNode，以用来分享给其他NameNode --&gt;</span><br><span class="line">    &lt;!-- 必须允许至少3个节点。当然可以运行更多，但是必须是奇数个 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;qjournal://master1:8485;master2:8485;slave1:8485;slave2:8485;slave3:8485/mycluster&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;!-- 声明journalnode本地磁盘存放数据的位置--&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;/home/rishinyan/data/hadoop/jn&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;!-- 配置隔离机制，即同一时刻只能有一台服务器对外响应，防止namenode脑裂 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;sshfence&lt;/value&gt;</span><br><span class="line">        &lt;value&gt;shell(true)&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    </span><br><span class="line">    &lt;!-- 使用隔离机制时需要ssh无秘钥登录--&gt;</span><br><span class="line">    &lt;!-- /home/rishinyan为用户目录，如果是其它用户，这里要替换 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;/home/rishinyan/.ssh/id_rsa&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;!-- namenode多目录配置 --&gt;</span><br><span class="line">    &lt;!-- 可配置多个namenode目录，用逗号分隔开 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;/rishinyan/data/hadoop/name&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;/rishinyan/data/hadoop/data&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;!-- 权限检查--&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.permissions.enabled&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;!-- 访问代理类：client，mycluster，active配置失败自动切换实现方式--&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.client.failover.proxy.provider.mycluster&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;!-- 自动故障转移启用 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<p>先按下<strong>esc</strong>，后输入:wq!保存并退出编辑</p>
<h4 id="YARN的配置">YARN的配置</h4>
<p>修改~/module/hadoop-3.3.4/etc/hadoop/yarn-site.xml</p>
<p>在&lt;configuration&gt;&lt;/configuration&gt;标签中添加内容</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br></pre></td><td class="code"><pre><span class="line">vi ~/module/hadoop-3.3.4/etc/hadoop/yarn-site.xml</span><br><span class="line"> </span><br><span class="line">    &lt;!-- 按i进入编辑 --&gt;</span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">        &lt;!-- reducer获取数据的方式,默认是shuffle --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    </span><br><span class="line">    &lt;!--启用resourcemanager ha--&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.ha.enabled&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    </span><br><span class="line">    &lt;!--声明两台resourcemanager的地址--&gt;</span><br><span class="line">    &lt;!-- 标识集群中的RM。如果设置该选项，需要确保所有的RMs在配置中都有自己的id。 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.cluster-id&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;cluster-yarn&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    </span><br><span class="line">    &lt;!-- RMs的逻辑id列表。可以自定义，此处设置为“rm1，rm2”。后面的配置将引用该id。 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.ha.rm-ids&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;rm1,rm2&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    </span><br><span class="line">    &lt;!-- 指定RM对应的主机名 --&gt;</span><br><span class="line">    &lt;!-- 可替换为192.168.2.246 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.hostname.rm1&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;master1&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    </span><br><span class="line">    &lt;!-- 可替换为192.168.2.247 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.hostname.rm2&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;master2&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    </span><br><span class="line">    &lt;!--yarn的web访问URI--&gt;</span><br><span class="line">    &lt;!-- 可替换为192.168.2.246 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.webapp.address.rm1&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;master1:8088&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    </span><br><span class="line">    &lt;!-- 可替换为192.168.2.247 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.webapp.address.rm2&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;master2:8088&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    </span><br><span class="line">    &lt;!--指定集成的ZooKeeper的服务地址--&gt; </span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.zk-address&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;slave1:2181,slave2:2181,slave3:2181&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    </span><br><span class="line">    &lt;!--启用自动恢复--&gt; </span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.recovery.enabled&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    </span><br><span class="line">    &lt;!--指定resourcemanager的状态信息存储在zookeeper集群--&gt; </span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.store.class&lt;/name&gt;     </span><br><span class="line">        &lt;value&gt;org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    </span><br><span class="line">    &lt;!-- 启用yarn ui2 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">            &lt;name&gt;yarn.webapp.ui2.enable&lt;/name&gt;</span><br><span class="line">            &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    </span><br><span class="line">    &lt;!--开启日志聚合。日志聚合会在应用程序完成后收集每个容器的日志，并将这些日志移动到文件系统中--&gt;</span><br><span class="line">    &lt;!-- 可以配置“yarn.nodemanager.remote-app-log-dir”和“ yarn.nodemanager.remote-app-log-dir-suffix”属性来确定将这些日志移至何处 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    </span><br><span class="line">    &lt;!-- yarn收集的日志保留时间，以秒为单位.2592000为30天 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">            &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt;</span><br><span class="line">            &lt;value&gt;2592000&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    </span><br><span class="line">    &lt;!-- 聚合日志后在hdfs的存放位置 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">            &lt;name&gt;yarn.nodemanager.remote-app-log-dir&lt;/name&gt;</span><br><span class="line">            &lt;value&gt;/yarn/logs&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    </span><br><span class="line">    &lt;!-- 聚合日志在本地的路径</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">            &lt;name&gt;yarn.nodemanager.local-dirs&lt;/name&gt;</span><br><span class="line">            &lt;value&gt;/data/app-log/local&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">     --&gt;</span><br><span class="line">    </span><br><span class="line">    &lt;!-- 日志历史服务的web url --&gt;</span><br><span class="line">    &lt;!-- 可替换为http://192.168.2.248:19888/jobhistory/logs --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.log.server.url&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;http://slave1:19888/jobhistory/logs&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    </span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.scheduler.address.rm1&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;master1:8030&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.scheduler.address.rm2&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;master2:8030&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.address.rm1&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;master1:8032&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.address.rm2&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;master2:8032&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;8192&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.scheduler.maximun-allocation-mb&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;102400&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.nodemanager.resource.cpu-vcores&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;32&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.nodemanager.pmem-check-enabled&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;false&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;false&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;!-- 可配置Yarn的调度策略</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.scheduler.class&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler&lt;/value&gt;</span><br><span class="line">        &lt;description&gt;设置Yarn的调度策略实现类&lt;/description&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.scheduler.fair.allocation.file&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;/home/rishinyan/program/hadoop-3.3.4/etc/hadoop/fair-scheduler.xml&lt;/value&gt;</span><br><span class="line">        &lt;description&gt;Fair调度策略的配置文件&lt;/description&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.resource-tracker.address.rm1&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;master1:8031&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.resource-tracker.address.rm2&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;master2:8031&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.am.max-attempts&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;4&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<p>先按下<strong>esc</strong>，后输入:wq!保存并退出编辑</p>
<h4 id="MapReduce的配置">MapReduce的配置</h4>
<p>修改~/module/hadoop-3.3.4/etc/hadoop/mapred-site.xml</p>
<p>在&lt;configuration&gt;&lt;/configuration&gt;标签中添加内容</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">vi ~/module/hadoop-3.3.4/etc/hadoop/mapred-site.xml</span><br><span class="line"></span><br><span class="line">&lt;!-- 按i进入编辑 --&gt;</span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;!-- 指定mr运行在yarn上 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    </span><br><span class="line">    &lt;!-- 开启历史日志服务，指定slave1为历史服务器 --&gt;</span><br><span class="line">    &lt;!-- 可替换为slave1:10020 或 192.168.2.248:10020 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;master1:10020&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    </span><br><span class="line">    &lt;!-- 历史日志服务的WEBUI --&gt;</span><br><span class="line">    &lt;!-- 可替换为slave1:19888 或 192.168.2.248:19888 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;master1:19888&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    </span><br><span class="line">    &lt;!-- 为MR应用程序添加了环境变量 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.app.mapreduce.am.env&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    </span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.map.env&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">        </span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.reduce.env&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<p>先按下<strong>esc</strong>，后输入:wq!保存并退出编辑</p>
<h4 id="将Hadoop分发到其他节点上">将Hadoop分发到其他节点上</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># master2可替换为/etc/hosts文件中对应的ip，192.168.2.247</span><br><span class="line">scp -r ~/module/hadoop-3.3.4  master2:~/module</span><br><span class="line"># slave1可替换为/etc/hosts文件中对应的ip，192.168.2.248</span><br><span class="line">scp -r ~/module/hadoop-3.3.4  slave1:~/module</span><br><span class="line"># slave2可替换为/etc/hosts文件中对应的ip，192.168.2.249</span><br><span class="line">scp -r ~/module/hadoop-3.3.4  slave2:~/module</span><br><span class="line"># slave3可替换为/etc/hosts文件中对应的ip，192.168.2.250</span><br><span class="line">scp -r ~/module/hadoop-3.3.4  slave3:~/module</span><br></pre></td></tr></table></figure>
<h4 id="在各个JournalNode节点上，启动journalnode服务">在各个JournalNode节点上，启动journalnode服务</h4>
<p>这里JournalNode节点为hdfs-site.xml中配置的master1，master2，slave1，slave2，slave3</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">~/module/hadoop-3.3.4/sbin/hadoop-daemon.sh start journalnode</span><br></pre></td></tr></table></figure>
<p>在命令行输入jps，当出现JournalNode说明启动成功</p>
<h4 id="在nn1即master1上，对其进行格式化-并启动">在nn1即master1上，对其进行格式化,并启动</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">~/module/hadoop-3.3.4/bin/hdfs namenode -format</span><br><span class="line">~/module/hadoop-3.3.4/sbin/hadoop-daemon.sh start namenode</span><br></pre></td></tr></table></figure>
<h4 id="在nn2即master2上，同步nn1的元数据信息">在nn2即master2上，同步nn1的元数据信息</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">~/module/hadoop-3.3.4/bin/hdfs namenode -bootstrapStandby</span><br></pre></td></tr></table></figure>
<p><font color='red'>如果再次提示是否重新格式化namenode要选择n</font></p>
<h4 id="初始化HA在Zookeeper中状态">初始化HA在Zookeeper中状态</h4>
<p>保证zookeeper集群已经启动</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 在master1上初始化HA在Zookeeper中状态</span><br><span class="line">~/module/hadoop-3.3.4/bin/hdfs zkfc -formatZK</span><br></pre></td></tr></table></figure>
<h4 id="启动HDFS服务，并验证自动故障转移">启动HDFS服务，并验证自动故障转移</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 在master1上启动HDFS</span><br><span class="line">~/module/hadoop-3.3.4/sbin/start-dfs.sh</span><br><span class="line"></span><br><span class="line"># 查看hdfs当前状态</span><br><span class="line">hdfs haadmin -getServiceState nn1</span><br><span class="line">hdfs haadmin -getServiceState nn2</span><br></pre></td></tr></table></figure>
<p>目前hdfs状态如图</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">#输入jps，查找NameNode前面的进程号，如20883 NameNode，则20883为进程id</span><br><span class="line">jps</span><br><span class="line"></span><br><span class="line"># 将Active NameNode进程kill , 可通过jps命名获取namenode的进程id</span><br><span class="line"># kill -9 namenode的进程id</span><br><span class="line"># 如kill -9 20883</span><br><span class="line"></span><br><span class="line"># 再次查看hdfs当前状态</span><br><span class="line">hdfs haadmin -getServiceState nn2</span><br></pre></td></tr></table></figure>
<p>在各个NameNode节点上启动ZKFailoverController进程，先在哪台机器启动，哪个机器的NameNode就是Active NameNode</p>
<p>杀死Active NameNode后，查看另一个StandBy NameNode是否变为Active NameNode</p>
<p>可通过<a target="_blank" rel="noopener" href="http://192.168.2.246:50070">http://master1:50070</a>或<a target="_blank" rel="noopener" href="http://192.168.2.247:50070">http://master2:50070</a>访问HDFS的web页面查看</p>
<h4 id="启动Yarn，并验证自动故障转移">启动Yarn，并验证自动故障转移</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 启动yarn</span><br><span class="line">~/module/hadoop-3.3.4/sbin/start-yarn.sh</span><br><span class="line"></span><br><span class="line"># 查看服务状态</span><br><span class="line">~/module/hadoop-3.3.4/bin/yarn rmadmin -getServiceState rm1</span><br><span class="line">~/module/hadoop-3.3.4/bin/yarn rmadmin -getServiceState rm2</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#输入jps，查找ResourceManager前面的进程号，如24485 ResourceManager，则24485为进程id</span><br><span class="line">jps</span><br><span class="line"></span><br><span class="line"># kill -9 ResourceManager的进程id</span><br><span class="line"># 如kill -9 24485</span><br><span class="line"></span><br><span class="line"># 查看服务状态，查看active是否变为standby</span><br><span class="line">~/module/hadoop-3.3.4/bin/yarn rmadmin -getServiceState rm2</span><br></pre></td></tr></table></figure>
<p>可通过<a target="_blank" rel="noopener" href="http://192.168.2.246:8088">http://master1:8088</a>访问Yarn的web页面</p>
<h4 id="启动日志历史服务">启动日志历史服务</h4>
<p>在配置日志历史服务的节点启动，这里是slave1</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">~/module/hadoop-3.3.4/sbin/mr-jobhistory-daemon.sh start historyserver</span><br></pre></td></tr></table></figure>
<p>命令行输入jps，出现JobHistoryServer则成功</p>
<p>可通过<a target="_blank" rel="noopener" href="http://192.168.2.248:19888/jobhistory/logs">http://slave1:19888/jobhistory/logs</a> 可查看日志</p>
<h1>HBase</h1>
<h2 id="准备-4">准备</h2>
<p>1.首先保证Zookeeper集群的正常部署并启动，参考Hadoop-HA安装部署文档的zookeeper部分</p>
<p>2.Hadoop集群的正常部署并启动，参考Hadoop-HA安装部署文档的Hadoop-ha部分</p>
<p>3.数据节点的~/installed目录中存在hbase-2.4.14-bin.tar.gz压缩包。这里选择master1节点</p>
<h2 id="安装步骤-4">安装步骤</h2>
<h3 id="解压HBase到指定目录">解压HBase到指定目录</h3>
<p>master1上将HBase解压至指定目录~/module</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf ~/installed/Hbase-2.4.14/hbase-2.4.14-bin.tar.gz -C ~/module/</span><br></pre></td></tr></table></figure>
<h3 id="配置hbase环境变量-bashrc">配置hbase环境变量~/.bashrc</h3>
<p>slave1,slave2,slave3均需配置./bash_profile文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi ~/.bash_profile</span><br></pre></td></tr></table></figure>
<p>按i进入编辑，在.bashrc文件尾部添加如下内容</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#HBASE_HOME为hbase的解压路径</span><br><span class="line">export HBASE_HOME=~/module/hbase-2.4.14</span><br><span class="line">export PATH=$PATH:$HBASE_HOME/bin</span><br></pre></td></tr></table></figure>
<p>先按下<strong>esc</strong>，后输入:wq!保存并退出编辑</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 查看配置是否成功</span><br><span class="line">source ~/.bash_profile</span><br><span class="line">hbase version</span><br></pre></td></tr></table></figure>
<p>当出现HBase 2.4.14,说明环境变量配置成功</p>
<h3 id="修改hbase-env-sh内容">修改hbase-env.sh内容</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">vi ~/module/hbase-2.4.14/conf/hbase-env.sh</span><br><span class="line"># 按i进入编辑</span><br><span class="line"># jdk的解压路径，如果解压路径改变，这里也要修改，这里参考Hadoop-HA安装部署文档的jdk部分</span><br><span class="line">export JAVA_HOME=/home/runyu/module/java</span><br><span class="line"># 因为hbase要启动hmaster、hregionServer，会产生pid，hbase要把pid记录在某个位置，默认是放在/tmp下。这里修改pid文件存放位置</span><br><span class="line">export HBASE_PID_DIR=/home/runyu/pids/hbase</span><br><span class="line"># 告诉HBase不管理自带的zookeeper</span><br><span class="line">export HBASE_MANAGES_ZK=false </span><br><span class="line"># hbase中hmaster和hregionserver日志存放位置</span><br><span class="line">export HBASE_LOG_DIR=/home/runyu/logs/hbase</span><br></pre></td></tr></table></figure>
<p>先按下<strong>esc</strong>，后输入:wq!保存并退出编辑</p>
<h3 id="修改hbase-site-xml内容">修改hbase-site.xml内容</h3>
<p>清空&lt;configuration&gt;&lt;/configuration&gt;标签内的内容，复制以下内容</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">每个节点创建日志和pid目录</span><br><span class="line">mkdir -p ~/pids/hbase</span><br><span class="line">mkdir -p ~/logs/hbase</span><br><span class="line">mkdir -p ~/data/hbase</span><br><span class="line">vi ~/module/hbase-2.4.14/conf/hbase-site.xml</span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">&lt;!-- 每个regionServer的共享目录,用来持久化Hbase,默认情况下在/tmp/hbase下面,mycluster为hdfs中namenode的集群，参考Hadoop-HA安装部署文档中core-site.xml的配置 --&gt;  </span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;hbase.rootdir&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;hdfs://mycluster/hbase&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line">	</span><br><span class="line">	&lt;!-- hbase集群模式,false表示hbase的单机，true表示是分布式模式 --&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;hbase.cluster.distributed&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;true&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line">	</span><br><span class="line">	&lt;!-- hbase依赖的zk地址 --&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;slave1:2181,slave2:2181,slave3:2181&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line">	</span><br><span class="line">	&lt;!-- ZooKeeper的zoo.conf中的配置。 快照的存储位置 --&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;/home/runyu/data/zkData&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line">	</span><br><span class="line">	&lt;!-- 不在本地文件系统中跑hbase，作为数据存储 --&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">	  	&lt;name&gt;hbase.unsafe.stream.capability.enforce&lt;/name&gt;</span><br><span class="line">	  	&lt;value&gt;false&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line">	</span><br><span class="line">	&lt;!-- HBase在Zookeeper中的根znode，所有的HBase对应要操作Zookeeper的znode都会用这个目录作为相对路径（默认情况下，所有HBase的Zookeeper文件路径都是相对路径，所以都会去这个目录下进行操作） --&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;zookeeper.znode.parent&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;/hbase&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line">	</span><br><span class="line">	&lt;!-- 本地文件系统 的临时文件夹 --&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">        &lt;name&gt;hbase.tmp.dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;/home/runyu/data/hbase/tmp&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line">	</span><br><span class="line">	&lt;!-- HBase Master的Web UI端口 --&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">        &lt;name&gt;hbase.master.info.port&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;60010&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hbase.wal.provider&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;filesystem&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<h3 id="编辑regionservers文件和创建backup-masters">编辑regionservers文件和创建backup-masters</h3>
<p>启动HRegionServer服务的节点</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">vi ~/module/hbase-2.4.14/conf/regionservers</span><br><span class="line"># 添加如下内容</span><br><span class="line"># slave1可替换为/etc/hosts文件中对应的ip，192.168.2.248</span><br><span class="line"># slave2可替换为/etc/hosts文件中对应的ip，192.168.2.249</span><br><span class="line"># slave3可替换为/etc/hosts文件中对应的ip，192.168.2.250</span><br><span class="line">slave1</span><br><span class="line">slave2</span><br><span class="line">slave3</span><br></pre></td></tr></table></figure>
<p>创建backup-masters</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vi ~/module/hbase-2.4.14/conf/backup-masters</span><br><span class="line"># 添加如下内容</span><br><span class="line"># master2可替换为/etc/hosts文件中对应的ip，192.168.2.247</span><br><span class="line">master2</span><br></pre></td></tr></table></figure>
<h3 id="软链接Hadoop配置文件到HBase">软链接Hadoop配置文件到HBase</h3>
<p>HBase读取Hadoop的配置</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ln -s ~/module/hadoop-3.3.4/etc/hadoop/core-site.xml ~/module/hbase-2.4.14/conf/core-site.xml</span><br><span class="line"></span><br><span class="line">ln -s ~/module/hadoop-3.3.4/etc/hadoop/hdfs-site.xml ~/module/hbase-2.4.14/conf/hdfs-site.xml</span><br></pre></td></tr></table></figure>
<h3 id="将HBase分发给其余的节点">将HBase分发给其余的节点</h3>
<p>这里选择了master1节点，将hbase分发到master2,slave1,slave2和slave3节点中</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># master2可替换为/etc/hosts文件中对应的ip，192.168.2.247</span><br><span class="line">scp -r ~/module/hbase-2.4.14/ master2:~/module/</span><br><span class="line"># slave1可替换为/etc/hosts文件中对应的ip，192.168.2.248</span><br><span class="line">scp -r ~/module/hbase-2.4.14/ slave1:~/module/</span><br><span class="line"># slave2可替换为/etc/hosts文件中对应的ip，192.168.2.249</span><br><span class="line">scp -r ~/module/hbase-2.4.14/ slave2:~/module/</span><br><span class="line"># slave3可替换为/etc/hosts文件中对应的ip，192.168.2.250</span><br><span class="line">scp -r ~/module/hbase-2.4.14/ slave3:~/module/</span><br></pre></td></tr></table></figure>
<h3 id="启动HBase">启动HBase</h3>
<p>这里选择master1节点</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">~/module/hbase-2.4.14/bin/start-hbase.sh</span><br></pre></td></tr></table></figure>
<h2 id="验证启动">验证启动</h2>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#输入jps，查看是否出现HRegionServer则成功</span><br><span class="line">jps</span><br></pre></td></tr></table></figure>
<p>master1出现HMaster和HRegionServer</p>
<p>启动成功后，可以通过“host:port”的方式来访问HBase管理页面，例如：</p>
<p><a target="_blank" rel="noopener" href="http://192.168.2.248:60010">http://slave1:60010</a></p>
<p><font color="red">如果集群之间的节点时间不同步，会导致regionserver无法启动，抛出ClockOutOfSyncException异常。</font></p>
<p>修复提示：</p>
<p>a、同步时间服务</p>
<p>b、属性：hbase.master.maxclockskew设置更大的值</p>
<h1>Hive</h1>
<h2 id="准备-5">准备</h2>
<p>1.Hadoop集群的正常部署并启动，参考Hadoop-HA安装部署文档的Hadoop-ha部分</p>
<p>2.正确安装mysql5.7,用来存放hive的元数据</p>
<p>3.数据节点的~/installed目录下有apache-hive-3.1.3-bin.tar.gz和mysql-connector-java-5.1.47.jar压缩包，这里选择master1节点</p>
<h2 id="安装步骤-5">安装步骤</h2>
<h3 id="解压Hive到指定目录">解压Hive到指定目录</h3>
<p>master1上将Hive解压至指定目录~/module</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf ~/installed/Hive-3.1.3/apache-hive-3.1.3-bin.tar.gz -C ~/module/</span><br><span class="line"></span><br><span class="line"># 将apache-hive-3.1.3-bin重命名为hive</span><br><span class="line">mv ~/module/apache-hive-3.1.3-bin/ ~/module/hive</span><br></pre></td></tr></table></figure>
<h3 id="配置hive环境变量-bashrc">配置hive环境变量~/.bashrc</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi ~/.bash_profile</span><br></pre></td></tr></table></figure>
<p>按i进入编辑，在.bashrc文件尾部添加如下内容</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#HIVE_HOME为hbase的解压路径</span><br><span class="line">export HIVE_HOME=/home/runyu/module/hive</span><br><span class="line">export PATH=$PATH:$HIVE_HOME/bin</span><br></pre></td></tr></table></figure>
<p>先按下<strong>esc</strong>，后输入:wq!保存并退出编辑</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 查看配置是否成功</span><br><span class="line">source ~/.bash_profile</span><br><span class="line">hive --version</span><br></pre></td></tr></table></figure>
<p>当出现Hive 3.1.2,说明环境变量配置成功</p>
<h3 id="修改-opt-module-hive-conf目录下的hive-env-sh-template名称为hive-env-sh">修改/opt/module/hive/conf目录下的hive-env.sh.template名称为hive-env.sh</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv ~/module/hive/conf/hive-env.sh.template ~/module/hive/conf/hive-env.sh</span><br></pre></td></tr></table></figure>
<h3 id="配置hive-env-sh文件">配置hive-env.sh文件</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">vi ~/module/hive/conf/hive-env.sh</span><br><span class="line"># 按i进入编辑模式</span><br><span class="line"></span><br><span class="line"># Hadoop的解压路径，如果解压路径改变，这里也要修改，这里参考Hadoop-HA安装部署文档的hadoop-ha部分</span><br><span class="line">export HADOOP_HOME=/home/runyu/module/hadoop-3.3.4</span><br><span class="line"># Hive配置文件的路径</span><br><span class="line">export HIVE_CONF_DIR=/home/runyu/module/hive/conf</span><br><span class="line">export HIVE_AUX_JARS_PATH=/home/runyu/module/hive/lib</span><br></pre></td></tr></table></figure>
<p>先按esc键，后输入:wq!保存并退出</p>
<h3 id="新建hive-site-xml文件，并添加配置项">新建hive-site.xml文件，并添加配置项</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br></pre></td><td class="code"><pre><span class="line"># 新建hive-site.xml文件</span><br><span class="line">touch ~/module/hive/conf/hive-site.xml</span><br><span class="line"></span><br><span class="line"># 添加配置项</span><br><span class="line">vi ~/module/hive/conf/hive-site.xml</span><br><span class="line"># 按i进入编辑模式</span><br><span class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;no&quot;?&gt;</span><br><span class="line">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">	&lt;!-- JDBC连接字符串。master1为mysql数据库ip地址，可替换为192.168.2.246，参考Hadoop-HA部署文档映射文件部分；3306为mysql的端口号；hive为数据库名；createDatabaseIfNotExist为创建hive数据库；不使用SSL --&gt;</span><br><span class="line">            &lt;property&gt;</span><br><span class="line">                     &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;</span><br><span class="line">                     &lt;value&gt;jdbc:mysql://master1:3306/hive?createDatabaseIfNotExist=true&amp;amp;useSSL=false&lt;/value&gt;</span><br><span class="line">            &lt;/property&gt;</span><br><span class="line">            &lt;!-- JDBC驱动 --&gt;</span><br><span class="line">            &lt;property&gt;</span><br><span class="line">                     &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;</span><br><span class="line">                     &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;</span><br><span class="line">            &lt;/property&gt;</span><br><span class="line">            &lt;!-- MYSQL数据库的用户名 --&gt;</span><br><span class="line">            &lt;property&gt;</span><br><span class="line">                     &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;</span><br><span class="line">                     &lt;value&gt;root&lt;/value&gt;</span><br><span class="line">            &lt;/property&gt;</span><br><span class="line">            &lt;!-- MYSQL数据库的用户名对应的密码 --&gt;</span><br><span class="line">            &lt;property&gt;</span><br><span class="line">                     &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;</span><br><span class="line">                     &lt;value&gt;Lxy932986998.&lt;/value&gt;</span><br><span class="line">            &lt;/property&gt;</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">            &lt;!-- 数据仓库在HDFS上的位置 --&gt;</span><br><span class="line">            &lt;property&gt;</span><br><span class="line">                     &lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt;</span><br><span class="line">                     &lt;value&gt;/hive/warehouse&lt;/value&gt;</span><br><span class="line">            &lt;/property&gt;</span><br><span class="line">            &lt;!-- 强制metastore的schema一致性，开启的话会校验在meatastore中存储信息的版本和hive的jar包中的版本的一致性，并且关闭自动schema迁移，用户必须手动的升级hive并且迁移schema，关闭的话只会在版本不一致时给出警告</span><br><span class="line">                  --&gt;</span><br><span class="line">            &lt;property&gt;</span><br><span class="line">                     &lt;name&gt;hive.metastore.schema.verification&lt;/name&gt;</span><br><span class="line">                     &lt;value&gt;false&lt;/value&gt;</span><br><span class="line">            &lt;/property&gt;</span><br><span class="line">    </span><br><span class="line">            &lt;!-- schema在不存在时，是否自动创建 --&gt;</span><br><span class="line">            &lt;property&gt;</span><br><span class="line">                     &lt;name&gt;datanucleus.schema.autoCreateAll&lt;/name&gt;</span><br><span class="line">                     &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">            &lt;/property&gt;</span><br><span class="line">            &lt;!-- 远程metastore的uri，用于metastore的客户端连接到远程metastore --&gt;</span><br><span class="line">            &lt;property&gt;</span><br><span class="line">                     &lt;name&gt;hive.metastore.uris&lt;/name&gt;</span><br><span class="line">                     &lt;value&gt;thrift://master1:9083,thrift://master2:9083&lt;/value&gt;</span><br><span class="line">            &lt;/property&gt;</span><br><span class="line">        &lt;!-- 绑定thrift服务的端口，主要用来建立与thrift服务连接 --&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                 &lt;name&gt;hive.server2.thrift.port&lt;/name&gt;</span><br><span class="line">                 &lt;value&gt;10000&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;!-- 配置thrift服务绑定的ip，需要在master1启动hive服务，thrift服务才能与master1建立连接，master1可替换为192.168.2.246，参考Hadoop-HA部署文档映射文件部分。thrift主要用来实现hiveserver2瘦客户端 --&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                 &lt;name&gt;hive.server2.thrift.bind.host&lt;/name&gt;</span><br><span class="line">                 &lt;value&gt;master1&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;!-- Hive元数据存储版本的验证 --&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                 &lt;name&gt;hive.metastore.event.db.notification.api.auth&lt;/name&gt;</span><br><span class="line">                 &lt;value&gt;false&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hive.repl.rootdir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;/hive/repl&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hive.exec.local.scratchdir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;/home/runyu/data/hive/hiveuser&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hive.download.resources.dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;/home/runyu/data/hive/tmp/$&#123;hive.session.id&#125;_resources&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hive.querylog.location&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;/home/runyu/logs/hive/qrylog&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hive.server2.logging.operation.log.location&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;/home/runyu/logs/hive/operationlog&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hive.zookeeper.quorum&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;slave1:2181,slave2:2181,slave3:2181&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hive.server2.support.dynamic.service.discovery&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hive.server2.zookeeper.namespace&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;hiveserver2_zk&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hive.server2.webui.host&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;master1&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hive.server2.webui.port&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;10002&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<p>先按下esc键，后输入:wq!保存并退出</p>
<h3 id="配置日志地址，修改hive-log4j-properties">配置日志地址，修改hive-log4j.properties</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 存放日志的目录</span><br><span class="line">mkdir -p ~/logs/hive/</span><br><span class="line"></span><br><span class="line"># 将hive-log4j2.properties.template改名为hive-log4j2.properties</span><br><span class="line">cp ~/module/hive/conf/hive-log4j2.properties.template ~/module/hive/conf/hive-log4j2.properties</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 编辑hive-log4j2.properties</span><br><span class="line">vi ~/module/hive/conf/hive-log4j2.properties</span><br><span class="line"></span><br><span class="line"># 将hive.log日志的位置改为hive主目录下的logs目录</span><br><span class="line">property.hive.log.dir = /home/runyu/logs/hive</span><br></pre></td></tr></table></figure>
<h3 id="拷贝jar包放入Hive主目录下的lib目录">拷贝jar包放入Hive主目录下的lib目录</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 拷贝JDBC的jar包放入Hive主目录下的lib目录</span><br><span class="line">cp mysql-connector-java-5.1.47.jar ~/module/hive/lib</span><br><span class="line"># 拷贝guava最新的jar包放入Hive主目录下的lib目录</span><br><span class="line">cp ~/module/hadoop-3.3.4/share/hadoop/hdfs/lib/guava-27.0-jre.jar ~/module/hive/lib/</span><br><span class="line"># 删除hive自带的旧guava包</span><br><span class="line">rm -f ~/module/hive/lib/guava-19.0.jar</span><br></pre></td></tr></table></figure>
<h3 id="分发hive">分发hive</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp -r ~/module/hive master2:~/module</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">#进入master2</span><br><span class="line">ssh master2</span><br><span class="line"></span><br><span class="line"># 编辑hive-site文件</span><br><span class="line">vi ~/hive/conf/hive-site.xml</span><br><span class="line"></span><br><span class="line">    &lt;!-- 修改属性为下面内容 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hive.server2.webui.host&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;master2&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hive.server2.thrift.bind.host&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;master2&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="启动hive">启动hive</h2>
<h3 id="初次启动hive要初始化">初次启动hive要初始化</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">~/module/hive/bin/schematool -dbType mysql -initSchema -verbose</span><br></pre></td></tr></table></figure>
<p>如果提示Error: Table ‘CTLGS’ already exists。请进入mysql删除hive数据库</p>
<h3 id="启动metastore">启动metastore</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup ~/module/hive/bin/hive --service metastore &gt; ~/logs/hive/metastore.log &amp; </span><br></pre></td></tr></table></figure>
<h3 id="启动hiveserver2">启动hiveserver2</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup ~/module/hive/bin/hive --service hiveserver2 &gt; ~/logs/hive/hiveserver2.log &amp;</span><br></pre></td></tr></table></figure>
<h1>ElasticSearch</h1>
<h2 id="准备-6">准备</h2>
<p>1.数据节点的~/installed目录中存在elasticsearch-8.4.3-linux-x86_64.tar.gz压缩包。这里选择slave1节点</p>
<h2 id="安装步骤-6">安装步骤</h2>
<h3 id="解压es到指定目录">解压es到指定目录</h3>
<p>slave1上将es解压至指定目录~/module</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf ~/installed/ElasticSearch-8.4.3/elasticsearch-8.4.3-linux-x86_64.tar.gz -C ~/module/</span><br></pre></td></tr></table></figure>
<h3 id="修改配置文件-2">修改配置文件</h3>
<h4 id="修改elasticsearch-yml">修改elasticsearch.yml</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi ~/module/elasticsearch-8.4.3/config/elasticsearch.yml</span><br></pre></td></tr></table></figure>
<p>按i进入编辑，修改文件的内容，如下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"># elasticsearch集群的名字</span><br><span class="line">cluster.name: myelasticsearch</span><br><span class="line"># 本节点的映射名，对应/etc/hosts文件，这里是slave1</span><br><span class="line">node.name: slave1</span><br><span class="line"># 网络节点</span><br><span class="line">network.host: slave1</span><br><span class="line"># 通信端口</span><br><span class="line">http.port: 9200</span><br><span class="line"># es的集群</span><br><span class="line">discovery.seed_hosts: [&quot;slave1&quot;, &quot;slave2&quot;,&quot;slave3&quot;]</span><br><span class="line">cluster.initial_master_nodes: [&quot;slave1&quot;, &quot;slave2&quot;,&quot;slave3&quot;]</span><br><span class="line"># 数据存放路径</span><br><span class="line">path.data: /home/runyu/data/elasticsearch</span><br><span class="line"># 日志存放路径</span><br><span class="line">path.logs: /home/runyu/logs/elasticsearch</span><br><span class="line">bootstrap.memory_lock: false</span><br><span class="line">http.cors.enabled: true</span><br><span class="line">http.cors.allow-origin: &quot;*&quot;</span><br><span class="line">xpack.security.enabled: false</span><br></pre></td></tr></table></figure>
<p>先按下<strong>esc</strong>，后输入:wq!保存并退出编辑</p>
<h4 id="修改jvm-option配置文件">修改jvm.option配置文件</h4>
<p>根据服务器的内存大小，调整jvm堆内存大小</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi ~/module/elasticsearch-8.4.3/config/jvm.options</span><br></pre></td></tr></table></figure>
<p>按i进入编辑，修改文件的内容，如下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-Xms4g</span><br><span class="line">-Xmx4g</span><br></pre></td></tr></table></figure>
<p>先按下<strong>esc</strong>，后输入:wq!保存并退出编辑</p>
<h4 id="将已经安装好的elasticsearch分发到其他节点">将已经安装好的elasticsearch分发到其他节点</h4>
<p>这里选择了slave1节点，将elasticsearch分发到slave2和slave3节点中</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># slave2可替换为/etc/hosts文件中对应的ip，192.168.2.249</span><br><span class="line">scp -r ~/module/elasticsearch-8.4.3/ slave2:~/module/</span><br><span class="line"># slave3可替换为/etc/hosts文件中对应的ip，192.168.2.250</span><br><span class="line">scp -r ~/module/elasticsearch-8.4.3/ slave3:~/module/</span><br></pre></td></tr></table></figure>
<h4 id="修改其余节点的配置文件">修改其余节点的配置文件</h4>
<p>修改slave2和slave3节点的elasticsearch的elasticsearch.yml文件<br>
这里用slave2举例，slave3进行相似操作</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi ~/module/elasticsearch-8.4.3/config/elasticsearch.yml</span><br></pre></td></tr></table></figure>
<p>按i进入编辑，修改文件的内容，如下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 本节点的映射名，对应/etc/hosts文件，这里是slave2</span><br><span class="line">node.name: slave2</span><br><span class="line"># 网络节点</span><br><span class="line">network.host: slave2</span><br></pre></td></tr></table></figure>
<p>先按下<strong>esc</strong>，后输入:wq!保存并退出编辑<br>
slave3也进行相似的操作，将slave1换为slave3</p>
<h3 id="修改系统配置">修改系统配置</h3>
<p>es服务对服务器的资源要求较多，包括内存大小，线程数，需要给runyu用户解开资源的限制</p>
<h4 id="普通用户打开文件的最大数限制">普通用户打开文件的最大数限制</h4>
<p>es需要大量的创建索引文件，需要大量的打开系统的文件。所以需要解除linux系统中打开文件最大数目的限制，不然会抛出错误，如下<br>
max file descriptors [4096] for elasticsearch process likely too low, increase to at least [65536]</p>
<p>es集群的所有节点都需要打开文件数据的限制</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vi /etc/security/limits.conf</span><br></pre></td></tr></table></figure>
<p>会提示输入runyu用户的密码，输入密码后<br>
按i进入编辑，在文件末尾追加内容，如下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">* soft nofile 65536</span><br><span class="line">* hard nofile 131072</span><br><span class="line">* soft nproc 2048</span><br><span class="line">* hard nproc 4096</span><br></pre></td></tr></table></figure>
<p>先按下<strong>esc</strong>，后输入:wq!保存并退出编辑</p>
<h4 id="普通用户启动线程数限制">普通用户启动线程数限制</h4>
<p>修改普通用户可以创建的最大线程数，用户可创建线程数太小，会导致<br>
max number of threads [1024] for user [es] likely too low, increase to at least [4096]</p>
<p>es集群的所有节点都需要修改</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vi /etc/security/limits.d/90-nproc.conf</span><br></pre></td></tr></table></figure>
<p>按i进入编辑，在修改文件内容，如下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">* soft nofile 65536</span><br><span class="line">* hard nofile 131072</span><br><span class="line">* soft nproc 2048</span><br><span class="line">* soft nproc 4096</span><br></pre></td></tr></table></figure>
<p>先按下<strong>esc</strong>，后输入:wq!保存并退出编辑</p>
<h4 id="普通用户调大虚拟内存">普通用户调大虚拟内存</h4>
<p>最大虚拟内存太小，导致抛出错误<br>
max virtual memory areas vm.max_map_count [65530] likely too low, increase to at least [262144]</p>
<p>es集群的所有节点都需要调大虚拟内存</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vi /etc/sysctl.conf</span><br></pre></td></tr></table></figure>
<p>按i进入编辑，在文件末尾追加内容，如下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vm.max_map_count=262144</span><br></pre></td></tr></table></figure>
<p>先按下<strong>esc</strong>，后输入:wq!保存并退出编辑<br>
执行以下命令，使配置生效</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sysctl -p</span><br></pre></td></tr></table></figure>
<p>注：当节点修改完系统配置，需要重新连接secureCRT或xsehll才可生效</p>
<h2 id="启动elasticsearch">启动elasticsearch</h2>
<p>对与elasticsearch上的节点使用启动命令，启动es服务</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup ~/module/elasticsearch-8.4.3/bin/elasticsearch &gt; ~/logs/elasticsearch/elasticsearch.log &amp;</span><br></pre></td></tr></table></figure>
<p>启动elasticsearch后，jsp可看到es服务进程，并且访问页面，看到es启动后的一些信息<br>
<a target="_blank" rel="noopener" href="http://slave1:9200/?pretty">http://slave1:9200/?pretty</a></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://blog.rishinyan.top">Rishinyan</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://blog.rishinyan.top/HadoopDeployment/">https://blog.rishinyan.top/HadoopDeployment/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://blog.rishinyan.top" target="_blank">Rishinyan</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Hadoop/">Hadoop</a></div><div class="post-share"><div class="social-share" data-image="https://ff09945.webp.li/MorishimaHaruka_3.png" data-sites="twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="https://ff09945.webp.li/watch_neko.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Rishinyan</div><div class="author-info-description">Rishinyan's Blog</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">7</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">3</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">2</div></a></div><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/hentaiacg" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:shinyanri@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a><a class="social-icon" href="/atom.xml" target="_blank" title=""><i class="fas fa-rss"></i></a><a class="social-icon" href="https://weibo.com/u/3219469802" target="_blank" title="Weibo"><i class="fab fa-weibo" style="color: #d70f0f;"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">Hadoop</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9Linux%E7%9A%84%E4%B8%BB%E6%9C%BA%E6%98%A0%E5%B0%84%E6%96%87%E4%BB%B6"><span class="toc-number">1.1.</span> <span class="toc-text">修改Linux的主机映射文件</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B3%E9%97%ADSelinux%E5%92%8C%E9%98%B2%E7%81%AB%E5%A2%99"><span class="toc-number">1.2.</span> <span class="toc-text">关闭Selinux和防火墙</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#SSH%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95%E9%85%8D%E7%BD%AE"><span class="toc-number">1.3.</span> <span class="toc-text">SSH免密登录配置</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%BE%E7%BD%AE%E6%97%B6%E9%97%B4%E5%90%8C%E6%AD%A5"><span class="toc-number">1.4.</span> <span class="toc-text">设置时间同步</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#JDK%E5%AE%89%E8%A3%85"><span class="toc-number">1.5.</span> <span class="toc-text">JDK安装</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%87%86%E5%A4%87"><span class="toc-number">1.5.1.</span> <span class="toc-text">准备</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%89%E8%A3%85%E6%AD%A5%E9%AA%A4"><span class="toc-number">1.5.2.</span> <span class="toc-text">安装步骤</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BB%E8%8A%82%E7%82%B9master1%E8%A7%A3%E5%8E%8Bjdk-8u281-linux-x64-tar-gz%E7%9A%84%E5%8E%8B%E7%BC%A9%E5%8C%85"><span class="toc-number">1.5.2.1.</span> <span class="toc-text">主节点master1解压jdk-8u281-linux-x64.tar.gz的压缩包</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AEjdk%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F-bashrc"><span class="toc-number">1.5.2.2.</span> <span class="toc-text">配置jdk环境变量~&#x2F;.bashrc</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B5%8B%E8%AF%95%E6%98%AF%E5%90%A6%E5%AE%89%E8%A3%85%E6%88%90%E5%8A%9F"><span class="toc-number">1.5.2.3.</span> <span class="toc-text">测试是否安装成功</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B0%86%E8%A7%A3%E5%8E%8B%E5%A5%BD%E7%9A%84jdk%E5%88%86%E5%8F%91%E7%BB%99%E5%85%B6%E4%BB%96%E8%8A%82%E7%82%B9"><span class="toc-number">1.5.2.4.</span> <span class="toc-text">将解压好的jdk分发给其他节点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E5%90%84%E4%B8%AA%E8%8A%82%E7%82%B9%E7%9A%84Java%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F"><span class="toc-number">1.5.2.5.</span> <span class="toc-text">配置各个节点的Java环境变量</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#zookeeper%E5%AE%89%E8%A3%85"><span class="toc-number">1.6.</span> <span class="toc-text">zookeeper安装</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%87%86%E5%A4%87-2"><span class="toc-number">1.6.1.</span> <span class="toc-text">准备</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%89%E8%A3%85%E6%AD%A5%E9%AA%A4-2"><span class="toc-number">1.6.2.</span> <span class="toc-text">安装步骤</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A7%A3%E5%8E%8Bapache-zookeeper-3-7-1-bin-tar-gz%E5%88%B0%E6%8C%87%E5%AE%9A%E7%9B%AE%E5%BD%95-module-%E4%B8%8B"><span class="toc-number">1.6.2.1.</span> <span class="toc-text">解压apache-zookeeper-3.7.1-bin.tar.gz到指定目录~&#x2F;module&#x2F;下</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E7%9B%AE%E5%BD%95%EF%BC%8C%E7%94%A8%E6%9D%A5%E5%AD%98%E6%94%BE%E6%95%B0%E6%8D%AE%E5%92%8C%E6%97%A5%E5%BF%97"><span class="toc-number">1.6.2.2.</span> <span class="toc-text">创建目录，用来存放数据和日志</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%87%8D%E5%91%BD%E5%90%8Dzoo-sample-cfg%E4%B8%BAzoo-cfg"><span class="toc-number">1.6.2.3.</span> <span class="toc-text">重命名zoo_sample.cfg为zoo.cfg</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-number">1.6.2.4.</span> <span class="toc-text">修改配置文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9C%A8zkData%E7%9B%AE%E5%BD%95%E4%B8%8B%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AAmyid%E7%9A%84%E6%96%87%E4%BB%B6"><span class="toc-number">1.6.2.5.</span> <span class="toc-text">在zkData目录下创建一个myid的文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BC%96%E8%BE%91myid%E6%96%87%E4%BB%B6"><span class="toc-number">1.6.2.6.</span> <span class="toc-text">编辑myid文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AEzookeeper%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F-bashrc"><span class="toc-number">1.6.2.7.</span> <span class="toc-text">配置zookeeper环境变量~&#x2F;.bashrc</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8B%B7%E8%B4%9D%E9%85%8D%E7%BD%AE%E5%A5%BD%E7%9A%84zookeeper%E5%88%86%E5%8F%91%E5%88%B0%E5%85%B6%E4%BB%96%E6%95%B0%E6%8D%AE%E8%8A%82%E7%82%B9%E4%B8%8A"><span class="toc-number">1.6.2.8.</span> <span class="toc-text">拷贝配置好的zookeeper分发到其他数据节点上</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B6%E4%BB%96%E6%95%B0%E6%8D%AE%E8%8A%82%E7%82%B9%E4%BF%AE%E6%94%B9%E5%88%86%E5%8F%91%E8%8A%82%E7%82%B9%E7%9A%84myid%E6%96%87%E4%BB%B6"><span class="toc-number">1.6.2.9.</span> <span class="toc-text">其他数据节点修改分发节点的myid文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%89%80%E6%9C%89%E6%95%B0%E6%8D%AE%E8%8A%82%E7%82%B9%E5%90%AF%E5%8A%A8zookeeper"><span class="toc-number">1.6.2.10.</span> <span class="toc-text">所有数据节点启动zookeeper</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9F%A5%E7%9C%8B%E7%8A%B6%E6%80%81"><span class="toc-number">1.6.3.</span> <span class="toc-text">查看状态</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HadoopHA%E5%AE%89%E8%A3%85"><span class="toc-number">1.7.</span> <span class="toc-text">HadoopHA安装</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%87%86%E5%A4%87-3"><span class="toc-number">1.7.1.</span> <span class="toc-text">准备</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%89%E8%A3%85%E6%AD%A5%E9%AA%A4-3"><span class="toc-number">1.7.2.</span> <span class="toc-text">安装步骤</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A7%A3%E5%8E%8Bapache-hadoop-3-3-4-tar-gz%E5%88%B0-rishinyan-module-%E7%9B%AE%E5%BD%95%E4%B8%8B"><span class="toc-number">1.7.2.1.</span> <span class="toc-text">解压apache-hadoop-3.3.4.tar.gz到&#x2F;rishinyan&#x2F;module&#x2F;目录下</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B0%86hadoop%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F"><span class="toc-number">1.7.2.2.</span> <span class="toc-text">将hadoop配置环境变量</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B5%8B%E8%AF%95%E6%98%AF%E5%90%A6%E5%AE%89%E8%A3%85%E6%88%90%E5%8A%9F-2"><span class="toc-number">1.7.2.3.</span> <span class="toc-text">测试是否安装成功</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E8%8A%82%E7%82%B9%E9%85%8D%E7%BD%AE"><span class="toc-number">1.7.2.4.</span> <span class="toc-text">数据节点配置</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#HDFS%E7%9A%84%E9%85%8D%E7%BD%AE"><span class="toc-number">1.7.2.5.</span> <span class="toc-text">HDFS的配置</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#YARN%E7%9A%84%E9%85%8D%E7%BD%AE"><span class="toc-number">1.7.2.6.</span> <span class="toc-text">YARN的配置</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#MapReduce%E7%9A%84%E9%85%8D%E7%BD%AE"><span class="toc-number">1.7.2.7.</span> <span class="toc-text">MapReduce的配置</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B0%86Hadoop%E5%88%86%E5%8F%91%E5%88%B0%E5%85%B6%E4%BB%96%E8%8A%82%E7%82%B9%E4%B8%8A"><span class="toc-number">1.7.2.8.</span> <span class="toc-text">将Hadoop分发到其他节点上</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9C%A8%E5%90%84%E4%B8%AAJournalNode%E8%8A%82%E7%82%B9%E4%B8%8A%EF%BC%8C%E5%90%AF%E5%8A%A8journalnode%E6%9C%8D%E5%8A%A1"><span class="toc-number">1.7.2.9.</span> <span class="toc-text">在各个JournalNode节点上，启动journalnode服务</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9C%A8nn1%E5%8D%B3master1%E4%B8%8A%EF%BC%8C%E5%AF%B9%E5%85%B6%E8%BF%9B%E8%A1%8C%E6%A0%BC%E5%BC%8F%E5%8C%96-%E5%B9%B6%E5%90%AF%E5%8A%A8"><span class="toc-number">1.7.2.10.</span> <span class="toc-text">在nn1即master1上，对其进行格式化,并启动</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9C%A8nn2%E5%8D%B3master2%E4%B8%8A%EF%BC%8C%E5%90%8C%E6%AD%A5nn1%E7%9A%84%E5%85%83%E6%95%B0%E6%8D%AE%E4%BF%A1%E6%81%AF"><span class="toc-number">1.7.2.11.</span> <span class="toc-text">在nn2即master2上，同步nn1的元数据信息</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%9D%E5%A7%8B%E5%8C%96HA%E5%9C%A8Zookeeper%E4%B8%AD%E7%8A%B6%E6%80%81"><span class="toc-number">1.7.2.12.</span> <span class="toc-text">初始化HA在Zookeeper中状态</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8HDFS%E6%9C%8D%E5%8A%A1%EF%BC%8C%E5%B9%B6%E9%AA%8C%E8%AF%81%E8%87%AA%E5%8A%A8%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB"><span class="toc-number">1.7.2.13.</span> <span class="toc-text">启动HDFS服务，并验证自动故障转移</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8Yarn%EF%BC%8C%E5%B9%B6%E9%AA%8C%E8%AF%81%E8%87%AA%E5%8A%A8%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB"><span class="toc-number">1.7.2.14.</span> <span class="toc-text">启动Yarn，并验证自动故障转移</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8%E6%97%A5%E5%BF%97%E5%8E%86%E5%8F%B2%E6%9C%8D%E5%8A%A1"><span class="toc-number">1.7.2.15.</span> <span class="toc-text">启动日志历史服务</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">HBase</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%87%86%E5%A4%87-4"><span class="toc-number">2.1.</span> <span class="toc-text">准备</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E8%A3%85%E6%AD%A5%E9%AA%A4-4"><span class="toc-number">2.2.</span> <span class="toc-text">安装步骤</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A3%E5%8E%8BHBase%E5%88%B0%E6%8C%87%E5%AE%9A%E7%9B%AE%E5%BD%95"><span class="toc-number">2.2.1.</span> <span class="toc-text">解压HBase到指定目录</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%85%8D%E7%BD%AEhbase%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F-bashrc"><span class="toc-number">2.2.2.</span> <span class="toc-text">配置hbase环境变量~&#x2F;.bashrc</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9hbase-env-sh%E5%86%85%E5%AE%B9"><span class="toc-number">2.2.3.</span> <span class="toc-text">修改hbase-env.sh内容</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9hbase-site-xml%E5%86%85%E5%AE%B9"><span class="toc-number">2.2.4.</span> <span class="toc-text">修改hbase-site.xml内容</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%96%E8%BE%91regionservers%E6%96%87%E4%BB%B6%E5%92%8C%E5%88%9B%E5%BB%BAbackup-masters"><span class="toc-number">2.2.5.</span> <span class="toc-text">编辑regionservers文件和创建backup-masters</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BD%AF%E9%93%BE%E6%8E%A5Hadoop%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E5%88%B0HBase"><span class="toc-number">2.2.6.</span> <span class="toc-text">软链接Hadoop配置文件到HBase</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B0%86HBase%E5%88%86%E5%8F%91%E7%BB%99%E5%85%B6%E4%BD%99%E7%9A%84%E8%8A%82%E7%82%B9"><span class="toc-number">2.2.7.</span> <span class="toc-text">将HBase分发给其余的节点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8HBase"><span class="toc-number">2.2.8.</span> <span class="toc-text">启动HBase</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%AA%8C%E8%AF%81%E5%90%AF%E5%8A%A8"><span class="toc-number">2.3.</span> <span class="toc-text">验证启动</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">Hive</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%87%86%E5%A4%87-5"><span class="toc-number">3.1.</span> <span class="toc-text">准备</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E8%A3%85%E6%AD%A5%E9%AA%A4-5"><span class="toc-number">3.2.</span> <span class="toc-text">安装步骤</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A3%E5%8E%8BHive%E5%88%B0%E6%8C%87%E5%AE%9A%E7%9B%AE%E5%BD%95"><span class="toc-number">3.2.1.</span> <span class="toc-text">解压Hive到指定目录</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%85%8D%E7%BD%AEhive%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F-bashrc"><span class="toc-number">3.2.2.</span> <span class="toc-text">配置hive环境变量~&#x2F;.bashrc</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9-opt-module-hive-conf%E7%9B%AE%E5%BD%95%E4%B8%8B%E7%9A%84hive-env-sh-template%E5%90%8D%E7%A7%B0%E4%B8%BAhive-env-sh"><span class="toc-number">3.2.3.</span> <span class="toc-text">修改&#x2F;opt&#x2F;module&#x2F;hive&#x2F;conf目录下的hive-env.sh.template名称为hive-env.sh</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%85%8D%E7%BD%AEhive-env-sh%E6%96%87%E4%BB%B6"><span class="toc-number">3.2.4.</span> <span class="toc-text">配置hive-env.sh文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%B0%E5%BB%BAhive-site-xml%E6%96%87%E4%BB%B6%EF%BC%8C%E5%B9%B6%E6%B7%BB%E5%8A%A0%E9%85%8D%E7%BD%AE%E9%A1%B9"><span class="toc-number">3.2.5.</span> <span class="toc-text">新建hive-site.xml文件，并添加配置项</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E6%97%A5%E5%BF%97%E5%9C%B0%E5%9D%80%EF%BC%8C%E4%BF%AE%E6%94%B9hive-log4j-properties"><span class="toc-number">3.2.6.</span> <span class="toc-text">配置日志地址，修改hive-log4j.properties</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8B%B7%E8%B4%9Djar%E5%8C%85%E6%94%BE%E5%85%A5Hive%E4%B8%BB%E7%9B%AE%E5%BD%95%E4%B8%8B%E7%9A%84lib%E7%9B%AE%E5%BD%95"><span class="toc-number">3.2.7.</span> <span class="toc-text">拷贝jar包放入Hive主目录下的lib目录</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E5%8F%91hive"><span class="toc-number">3.2.8.</span> <span class="toc-text">分发hive</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8hive"><span class="toc-number">3.3.</span> <span class="toc-text">启动hive</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9D%E6%AC%A1%E5%90%AF%E5%8A%A8hive%E8%A6%81%E5%88%9D%E5%A7%8B%E5%8C%96"><span class="toc-number">3.3.1.</span> <span class="toc-text">初次启动hive要初始化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8metastore"><span class="toc-number">3.3.2.</span> <span class="toc-text">启动metastore</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8hiveserver2"><span class="toc-number">3.3.3.</span> <span class="toc-text">启动hiveserver2</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">4.</span> <span class="toc-text">ElasticSearch</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%87%86%E5%A4%87-6"><span class="toc-number">4.1.</span> <span class="toc-text">准备</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E8%A3%85%E6%AD%A5%E9%AA%A4-6"><span class="toc-number">4.2.</span> <span class="toc-text">安装步骤</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A3%E5%8E%8Bes%E5%88%B0%E6%8C%87%E5%AE%9A%E7%9B%AE%E5%BD%95"><span class="toc-number">4.2.1.</span> <span class="toc-text">解压es到指定目录</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6-2"><span class="toc-number">4.2.2.</span> <span class="toc-text">修改配置文件</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9elasticsearch-yml"><span class="toc-number">4.2.2.1.</span> <span class="toc-text">修改elasticsearch.yml</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9jvm-option%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-number">4.2.2.2.</span> <span class="toc-text">修改jvm.option配置文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B0%86%E5%B7%B2%E7%BB%8F%E5%AE%89%E8%A3%85%E5%A5%BD%E7%9A%84elasticsearch%E5%88%86%E5%8F%91%E5%88%B0%E5%85%B6%E4%BB%96%E8%8A%82%E7%82%B9"><span class="toc-number">4.2.2.3.</span> <span class="toc-text">将已经安装好的elasticsearch分发到其他节点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9%E5%85%B6%E4%BD%99%E8%8A%82%E7%82%B9%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-number">4.2.2.4.</span> <span class="toc-text">修改其余节点的配置文件</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE"><span class="toc-number">4.2.3.</span> <span class="toc-text">修改系统配置</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%99%AE%E9%80%9A%E7%94%A8%E6%88%B7%E6%89%93%E5%BC%80%E6%96%87%E4%BB%B6%E7%9A%84%E6%9C%80%E5%A4%A7%E6%95%B0%E9%99%90%E5%88%B6"><span class="toc-number">4.2.3.1.</span> <span class="toc-text">普通用户打开文件的最大数限制</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%99%AE%E9%80%9A%E7%94%A8%E6%88%B7%E5%90%AF%E5%8A%A8%E7%BA%BF%E7%A8%8B%E6%95%B0%E9%99%90%E5%88%B6"><span class="toc-number">4.2.3.2.</span> <span class="toc-text">普通用户启动线程数限制</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%99%AE%E9%80%9A%E7%94%A8%E6%88%B7%E8%B0%83%E5%A4%A7%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98"><span class="toc-number">4.2.3.3.</span> <span class="toc-text">普通用户调大虚拟内存</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8elasticsearch"><span class="toc-number">4.3.</span> <span class="toc-text">启动elasticsearch</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/Jeff'sPlaylist/" title="Jeff's Playlist"><img src="https://ff09945.webp.li/MorishimaHaruka_3.png" onerror="this.onerror=null;this.src='https://ff09945.webp.li/MorishimaHaruka_2.png'" alt="Jeff's Playlist"/></a><div class="content"><a class="title" href="/Jeff'sPlaylist/" title="Jeff's Playlist">Jeff's Playlist</a><time datetime="2025-01-11T07:30:00.000Z" title="发表于 2025-01-11 15:30:00">2025-01-11</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/CentosCompliesHadoop/" title="Centos7.9 编译 Hadoop3.4.0"><img src="https://ff09945.webp.li/MorishimaHaruka_3.png" onerror="this.onerror=null;this.src='https://ff09945.webp.li/MorishimaHaruka_2.png'" alt="Centos7.9 编译 Hadoop3.4.0"/></a><div class="content"><a class="title" href="/CentosCompliesHadoop/" title="Centos7.9 编译 Hadoop3.4.0">Centos7.9 编译 Hadoop3.4.0</a><time datetime="2024-07-18T10:33:00.000Z" title="发表于 2024-07-18 18:33:00">2024-07-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/JupyterNotebookInstallation/" title="Jupyter Notebook 安装"><img src="https://ff09945.webp.li/MorishimaHaruka_3.png" onerror="this.onerror=null;this.src='https://ff09945.webp.li/MorishimaHaruka_2.png'" alt="Jupyter Notebook 安装"/></a><div class="content"><a class="title" href="/JupyterNotebookInstallation/" title="Jupyter Notebook 安装">Jupyter Notebook 安装</a><time datetime="2024-07-02T16:00:00.000Z" title="发表于 2024-07-03 00:00:00">2024-07-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/Kubernetes/" title="Kubernetes 安装"><img src="https://ff09945.webp.li/MorishimaHaruka_3.png" onerror="this.onerror=null;this.src='https://ff09945.webp.li/MorishimaHaruka_2.png'" alt="Kubernetes 安装"/></a><div class="content"><a class="title" href="/Kubernetes/" title="Kubernetes 安装">Kubernetes 安装</a><time datetime="2024-05-31T16:00:00.000Z" title="发表于 2024-06-01 00:00:00">2024-06-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/lxd/" title="LXD General Command"><img src="https://ff09945.webp.li/MorishimaHaruka_3.png" onerror="this.onerror=null;this.src='https://ff09945.webp.li/MorishimaHaruka_2.png'" alt="LXD General Command"/></a><div class="content"><a class="title" href="/lxd/" title="LXD General Command">LXD General Command</a><time datetime="2024-05-05T16:00:00.000Z" title="发表于 2024-05-06 00:00:00">2024-05-06</time></div></div></div></div></div></div></main><footer id="footer" style="background: transparent;"><div id="footer-wrap"><!-- display waves--><section class="main-hero-waves-area waves-area"></section><svg class="waves-svg1" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" viewBox="0 0 150 40" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M 0 30 Q 25 15, 50 30 T 100 30 T 150 30 V 50 H 0 Z"></path></defs><g class="parallax"><use href="#gentle-wave" x="48" y="0"></use><use href="#gentle-wave" x="48" y="3"></use><use href="#gentle-wave" x="48" y="5"></use><use href="#gentle-wave" x="48" y="7"></use></g></svg></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="前往评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><div class="js-pjax"><script>(async () => {
  const showKatex = () => {
    document.querySelectorAll('#article-container .katex').forEach(el => el.classList.add('katex-show'))
  }

  if (!window.katex_js_css) {
    window.katex_js_css = true
    await btf.getCSS('https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css')
    if (true) {
      await btf.getScript('https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js')
    }
  }

  showKatex()
})()</script><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = null

  const commentCount = n => {
    const isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
    if (isCommentCount) {
      isCommentCount.textContent= n
    }
  }

  const initGitalk = (el, path) => {
    if (isShuoshuo) {
      window.shuoshuoComment.destroyGitalk = () => {
        if (el.children.length) {
          el.innerHTML = ''
          el.classList.add('no-comment')
        }
      }
    }

    const gitalk = new Gitalk({
      clientID: 'Ov23liLi5I2iIluEap7Y',
      clientSecret: '51f16c78325c36c02732e0455ab59c8e6537791c',
      repo: 'hentaiacg.github.io',
      owner: 'hentaiacg',
      admin: ['hentaiacg'],
      updateCountCallback: commentCount,
      ...option,
      id: isShuoshuo ? path : (option && option.id) || '60ff9c7b07e5292d408223b3ab8b5a5b'
    })

    gitalk.render('gitalk-container')
  }

  const loadGitalk = async(el, path) => {
    if (typeof Gitalk === 'function') initGitalk(el, path)
    else {
      await btf.getCSS('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css')
      await btf.getScript('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.js')
      initGitalk(el, path)
    }
  }

  if (isShuoshuo) {
    'Gitalk' === 'Gitalk'
      ? window.shuoshuoComment = { loadComment: loadGitalk }
      : window.loadOtherComment = loadGitalk
    return
  }

  if ('Gitalk' === 'Gitalk' || !false) {
    if (false) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
    else loadGitalk()
  } else {
    window.loadOtherComment = loadGitalk
  }
})()</script></div><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/fireworks.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>